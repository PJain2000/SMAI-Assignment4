{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('./Datasets_final/q2/train.csv',dtype=str)\n",
    "df2 = pd.read_csv('./Datasets_final/q2/test.csv',dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_ext(fn):\n",
    "    return fn+\".jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['image_file'] = df1['image_file'].apply(append_ext)\n",
    "df2['image_file'] = df2['image_file'].apply(append_ext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create train_datagen and test_datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the augmentation configuration we will use for training\n",
    "datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        validation_split=0.25)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize paths where images flow from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datagen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-11bbcfc3a465>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_generator = datagen.flow_from_dataframe(\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0mdataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mdirectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./Datasets_final/q2/train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mx_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'image_file'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0my_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'emotion'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datagen' is not defined"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_dataframe(\n",
    "        dataframe = df1,\n",
    "        directory = './Datasets_final/q2/train',\n",
    "        x_col = 'image_file',\n",
    "        y_col = 'emotion',\n",
    "        subset=\"training\",\n",
    "        batch_size = 16,\n",
    "        class_mode = 'categorical',\n",
    "        target_size = (150, 150))\n",
    "\n",
    "val_generator = datagen.flow_from_dataframe(\n",
    "        dataframe = df1,\n",
    "        directory = './Datasets_final/q2/train',\n",
    "        x_col = 'image_file',\n",
    "        y_col = 'emotion',\n",
    "        subset=\"validation\",\n",
    "        batch_size = 16,\n",
    "        class_mode = 'categorical',\n",
    "        target_size = (150, 150))\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "        dataframe = df2,\n",
    "        directory = './Datasets_final/q2/test',\n",
    "        x_col = 'image_file',\n",
    "        y_col = None,\n",
    "        batch_size = 16,\n",
    "        class_mode = None,\n",
    "        target_size = (150, 150))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inializing the CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "# Step 1 - Convolution\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (150, 150, 3), activation = 'relu'))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(activation = 'relu', units = 128))\n",
    "classifier.add(Dense(activation = 'sigmoid', units = 5))\n",
    "classifier.compile (optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 72, 72, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 41472)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               5308544   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 5,319,333\n",
      "Trainable params: 5,319,333\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "91/91 [==============================] - 24s 266ms/step - loss: 1.7422 - accuracy: 0.3462 - val_loss: 1.7099 - val_accuracy: 0.0333\n",
      "Epoch 2/40\n",
      "91/91 [==============================] - 24s 267ms/step - loss: 1.3080 - accuracy: 0.4526 - val_loss: 2.4180 - val_accuracy: 0.2217\n",
      "Epoch 3/40\n",
      "91/91 [==============================] - 24s 265ms/step - loss: 1.0866 - accuracy: 0.5625 - val_loss: 2.2838 - val_accuracy: 0.3710\n",
      "Epoch 4/40\n",
      "91/91 [==============================] - 24s 267ms/step - loss: 0.9272 - accuracy: 0.6264 - val_loss: 1.8301 - val_accuracy: 0.2537\n",
      "Epoch 5/40\n",
      "91/91 [==============================] - 24s 268ms/step - loss: 0.7827 - accuracy: 0.6875 - val_loss: 1.7489 - val_accuracy: 0.2857\n",
      "Epoch 6/40\n",
      "91/91 [==============================] - 24s 268ms/step - loss: 0.6579 - accuracy: 0.7404 - val_loss: 2.2977 - val_accuracy: 0.2623\n",
      "Epoch 7/40\n",
      "91/91 [==============================] - 24s 265ms/step - loss: 0.6089 - accuracy: 0.7782 - val_loss: 2.9822 - val_accuracy: 0.1919\n",
      "Epoch 8/40\n",
      "91/91 [==============================] - 24s 265ms/step - loss: 0.5190 - accuracy: 0.8036 - val_loss: 3.0159 - val_accuracy: 0.2559\n",
      "Epoch 9/40\n",
      "91/91 [==============================] - 24s 266ms/step - loss: 0.4414 - accuracy: 0.8324 - val_loss: 3.0532 - val_accuracy: 0.2644\n",
      "Epoch 10/40\n",
      "91/91 [==============================] - 24s 265ms/step - loss: 0.4155 - accuracy: 0.8413 - val_loss: 3.7148 - val_accuracy: 0.2409\n",
      "Epoch 11/40\n",
      "91/91 [==============================] - 24s 265ms/step - loss: 0.3919 - accuracy: 0.8496 - val_loss: 5.6846 - val_accuracy: 0.2111\n",
      "Epoch 12/40\n",
      "91/91 [==============================] - 24s 264ms/step - loss: 0.3482 - accuracy: 0.8626 - val_loss: 4.5487 - val_accuracy: 0.1919\n",
      "Epoch 13/40\n",
      "91/91 [==============================] - 24s 265ms/step - loss: 0.3336 - accuracy: 0.8826 - val_loss: 7.0461 - val_accuracy: 0.2004\n",
      "Epoch 14/40\n",
      "91/91 [==============================] - 24s 262ms/step - loss: 0.2921 - accuracy: 0.8887 - val_loss: 2.7124 - val_accuracy: 0.2324\n",
      "Epoch 15/40\n",
      "91/91 [==============================] - 24s 264ms/step - loss: 0.2838 - accuracy: 0.8901 - val_loss: 5.2935 - val_accuracy: 0.2367\n",
      "Epoch 16/40\n",
      "91/91 [==============================] - 24s 263ms/step - loss: 0.2884 - accuracy: 0.8949 - val_loss: 3.5699 - val_accuracy: 0.3113\n",
      "Epoch 17/40\n",
      "91/91 [==============================] - 24s 264ms/step - loss: 0.2246 - accuracy: 0.9155 - val_loss: 2.6954 - val_accuracy: 0.2537\n",
      "Epoch 18/40\n",
      "91/91 [==============================] - 24s 267ms/step - loss: 0.2294 - accuracy: 0.9176 - val_loss: 5.6435 - val_accuracy: 0.2601\n",
      "Epoch 19/40\n",
      "91/91 [==============================] - 24s 264ms/step - loss: 0.2427 - accuracy: 0.9162 - val_loss: 4.7507 - val_accuracy: 0.2836\n",
      "Epoch 20/40\n",
      "91/91 [==============================] - 24s 260ms/step - loss: 0.2253 - accuracy: 0.9190 - val_loss: 4.7612 - val_accuracy: 0.2068\n",
      "Epoch 21/40\n",
      "91/91 [==============================] - 24s 260ms/step - loss: 0.1614 - accuracy: 0.9348 - val_loss: 5.5484 - val_accuracy: 0.2324\n",
      "Epoch 22/40\n",
      "91/91 [==============================] - 24s 264ms/step - loss: 0.2211 - accuracy: 0.9299 - val_loss: 6.6084 - val_accuracy: 0.2260\n",
      "Epoch 23/40\n",
      "91/91 [==============================] - 24s 260ms/step - loss: 0.1819 - accuracy: 0.9382 - val_loss: 5.3171 - val_accuracy: 0.2303\n",
      "Epoch 24/40\n",
      "91/91 [==============================] - 24s 261ms/step - loss: 0.1699 - accuracy: 0.9389 - val_loss: 5.0773 - val_accuracy: 0.1919\n",
      "Epoch 25/40\n",
      "91/91 [==============================] - 24s 261ms/step - loss: 0.1852 - accuracy: 0.9423 - val_loss: 3.4832 - val_accuracy: 0.2814\n",
      "Epoch 26/40\n",
      "91/91 [==============================] - 24s 261ms/step - loss: 0.1685 - accuracy: 0.9375 - val_loss: 6.1725 - val_accuracy: 0.2495\n",
      "Epoch 27/40\n",
      "91/91 [==============================] - 24s 261ms/step - loss: 0.2202 - accuracy: 0.9389 - val_loss: 5.9488 - val_accuracy: 0.2644\n",
      "Epoch 28/40\n",
      "91/91 [==============================] - 24s 264ms/step - loss: 0.1467 - accuracy: 0.9457 - val_loss: 8.0254 - val_accuracy: 0.2004\n",
      "Epoch 29/40\n",
      "91/91 [==============================] - 24s 260ms/step - loss: 0.1303 - accuracy: 0.9533 - val_loss: 3.5179 - val_accuracy: 0.2367\n",
      "Epoch 30/40\n",
      "91/91 [==============================] - 25s 271ms/step - loss: 0.1253 - accuracy: 0.9499 - val_loss: 5.1924 - val_accuracy: 0.2751\n",
      "Epoch 31/40\n",
      "91/91 [==============================] - 24s 266ms/step - loss: 0.1279 - accuracy: 0.9547 - val_loss: 5.5766 - val_accuracy: 0.2239\n",
      "Epoch 32/40\n",
      "91/91 [==============================] - 24s 265ms/step - loss: 0.1361 - accuracy: 0.9588 - val_loss: 8.5232 - val_accuracy: 0.1792\n",
      "Epoch 33/40\n",
      "91/91 [==============================] - 24s 266ms/step - loss: 0.1351 - accuracy: 0.9602 - val_loss: 6.4352 - val_accuracy: 0.2687\n",
      "Epoch 34/40\n",
      "91/91 [==============================] - 25s 277ms/step - loss: 0.1174 - accuracy: 0.9622 - val_loss: 5.8331 - val_accuracy: 0.2431\n",
      "Epoch 35/40\n",
      "91/91 [==============================] - 26s 288ms/step - loss: 0.1431 - accuracy: 0.9602 - val_loss: 4.9284 - val_accuracy: 0.2495\n",
      "Epoch 36/40\n",
      "91/91 [==============================] - 23s 256ms/step - loss: 0.1018 - accuracy: 0.9677 - val_loss: 5.0219 - val_accuracy: 0.3070\n",
      "Epoch 37/40\n",
      "91/91 [==============================] - 26s 284ms/step - loss: 0.0989 - accuracy: 0.9657 - val_loss: 7.1798 - val_accuracy: 0.2388\n",
      "Epoch 38/40\n",
      "91/91 [==============================] - 27s 298ms/step - loss: 0.0899 - accuracy: 0.9705 - val_loss: 8.1967 - val_accuracy: 0.2281\n",
      "Epoch 39/40\n",
      "91/91 [==============================] - 24s 261ms/step - loss: 0.0870 - accuracy: 0.9712 - val_loss: 7.1078 - val_accuracy: 0.2495\n",
      "Epoch 40/40\n",
      "91/91 [==============================] - 23s 258ms/step - loss: 0.1487 - accuracy: 0.9670 - val_loss: 4.9618 - val_accuracy: 0.2623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x13a227690>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=val_generator.n//val_generator.batch_size\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "\n",
    "classifier.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=40\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8.853296279907227, 0.255159467458725]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.evaluate_generator(generator=val_generator, steps=STEP_SIZE_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 10s 296ms/step\n"
     ]
    }
   ],
   "source": [
    "pred=classifier.predict_generator(test_generator, steps=STEP_SIZE_TEST+1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_indices=np.argmax(pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(predicted_class_indices, columns=['emotion']).to_csv(\"./Datasets_final/q2/final_submission2.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
